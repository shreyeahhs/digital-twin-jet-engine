{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "0"
   },
   "source": [
    "# Digital Twin — Jet Engine Health & RUL (CMAPSS FD001–FD004)\n",
    "\n",
    "**Author:** Shreyas Gowda B  \n",
    "**Purpose:** A production‑ready notebook that loads NASA **CMAPSS** turbofan datasets (or synthesizes data),\n",
    "builds online features, trains an RUL model with uncertainty, and provides a live streaming simulator.\n",
    "\n",
    "This version is hardened to work with your file naming like `train_FD001`, `test_FD001`, `RUL_FD001` (with or without `.txt`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "1"
   },
   "source": [
    "## 0. Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "id": "2"
   },
   "source": [
    "### What this cell does\n",
    "\n",
    "- Imports libraries: `sys` for data handling, ML, plotting, and utilities.\n",
    "- Defines helper functions: `ensure`.\n",
    "- Produces visualizations (e.g., true vs predicted RUL, residual plots, or feature distributions).\n",
    "- All code remains unchanged; this cell-level note was added for clarity and maintainability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3",
    "outputId": "1014b9dc-d783-484a-a725-67fc69ed9a79"
   },
   "outputs": [],
   "source": [
    "import sys, subprocess, importlib\n",
    "def ensure(pkg, name=None):\n",
    "    try:\n",
    "        importlib.import_module(name or pkg)\n",
    "    except Exception:\n",
    "        print(f\"Installing {pkg}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
    "\n",
    "for p in [\"pandas\",\"numpy\",\"scikit-learn\",\"plotly\",\"ipywidgets\",\"tqdm\",\"joblib\",\"pyarrow\"]:\n",
    "    ensure(p)\n",
    "print(\"Environment ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "id": "4"
   },
   "source": [
    "## 1. Imports & Global Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "id": "5"
   },
   "source": [
    "### What this cell does\n",
    "\n",
    "- Imports libraries: `datetime, joblib, numpy, os, pandas, plotly.graph_objects, plotly.subplots, sklearn.ensemble, sklearn.metrics, sklearn.model_selection, sklearn.preprocessing, tqdm` for data handling, ML, plotting, and utilities.\n",
    "- Resolves filesystem paths (e.g., `DATA_ROOT`, `DATASET`) and locates data files robustly.\n",
    "- Fits a feature scaler (e.g., `StandardScaler`) to normalize inputs consistently across train/validation/inference.\n",
    "- Trains a regression model for RUL prediction (e.g., `GradientBoostingRegressor`).\n",
    "- Splits data into training/validation (or uses cross-validation) to estimate generalization performance.\n",
    "- Computes evaluation metrics (MAE/RMSE/R²) to quantify prediction accuracy.\n",
    "- Produces visualizations (e.g., true vs predicted RUL, residual plots, or feature distributions).\n",
    "- All code remains unchanged; this cell-level note was added for clarity and maintainability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6",
    "outputId": "fbce8600-ab68-4138-9e02-8a1f5284c9fc"
   },
   "outputs": [],
   "source": [
    "import os, glob, math, json, time, random, warnings\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import dump\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED); random.seed(RANDOM_SEED)\n",
    "\n",
    "# --- Set these for your machine ---\n",
    "DATA_ROOT = os.environ.get('CMAPSS_DIR', './CMAPSS')  # folder containing train_FD001, test_FD001, RUL_FD001\n",
    "DATASET   = os.environ.get('CMAPSS_SUBSET', 'FD001')  # FD001 | FD002 | FD003 | FD004\n",
    "# ----------------------------------\n",
    "\n",
    "ARTIFACT_DIR = './artifacts_v4'\n",
    "os.makedirs(ARTIFACT_DIR, exist_ok=True)\n",
    "\n",
    "USE_ROBUST_SCALER = True\n",
    "RUL_CAP = 125\n",
    "SEQ_WINDOW = 30\n",
    "USE_SYNTH_IF_MISSING = True\n",
    "\n",
    "print({'DATA_ROOT': DATA_ROOT, 'DATASET': DATASET, 'RUL_CAP': RUL_CAP, 'SEQ_WINDOW': SEQ_WINDOW})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "id": "7"
   },
   "source": [
    "## 2. Loader (handles `train_FD001` / `test_FD001` / `RUL_FD001`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "id": "8"
   },
   "source": [
    "### What this cell does\n",
    "\n",
    "- Loads dataset files (e.g., CMAPSS `train_FDxxx.txt`, `test_FDxxx.txt`, `RUL_FDxxx.txt`) into Pandas DataFrames.\n",
    "- Resolves filesystem paths (e.g., `DATA_ROOT`, `DATASET`) and locates data files robustly.\n",
    "- Defines helper functions: `_pick_one, _resolve_paths, _read_cmapss, load_cmapss_flexible, _map_cols, synth_cmapss_like`.\n",
    "- Engineers rolling-window features: `*_ma`, `*_std`, `*_diff`, plus a composite Health Index (HI) from z-scores.\n",
    "- All code remains unchanged; this cell-level note was added for clarity and maintainability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "id": "9",
    "outputId": "6ede6786-fbae-4089-a5d8-9958facab118"
   },
   "outputs": [],
   "source": [
    "def _pick_one(candidates):\n",
    "    for p in candidates:\n",
    "        if os.path.exists(p):\n",
    "            return p\n",
    "        hits = glob.glob(p)\n",
    "        if hits:\n",
    "            return hits[0]\n",
    "    return None\n",
    "\n",
    "def _resolve_paths(data_root: str, subset: str):\n",
    "    train_candidates = [\n",
    "        os.path.join(data_root, f\"train_{subset}.txt\"),\n",
    "        os.path.join(data_root, f\"train_{subset}\"),\n",
    "        os.path.join(data_root, f\"{subset}_train.txt\"),\n",
    "        os.path.join(data_root, f\"{subset}_train\"),\n",
    "    ]\n",
    "    test_candidates = [\n",
    "        os.path.join(data_root, f\"test_{subset}.txt\"),\n",
    "        os.path.join(data_root, f\"test_{subset}\"),\n",
    "        os.path.join(data_root, f\"{subset}_test.txt\"),\n",
    "        os.path.join(data_root, f\"{subset}_test\"),\n",
    "    ]\n",
    "    rul_candidates = [\n",
    "        os.path.join(data_root, f\"RUL_{subset}.txt\"),\n",
    "        os.path.join(data_root, f\"RUL_{subset}\"),\n",
    "        os.path.join(data_root, f\"{subset}_RUL.txt\"),\n",
    "        os.path.join(data_root, f\"{subset}_RUL\"),\n",
    "    ]\n",
    "    tr = _pick_one(train_candidates)\n",
    "    te = _pick_one(test_candidates)\n",
    "    ru = _pick_one(rul_candidates)\n",
    "    return tr, te, ru\n",
    "\n",
    "def _read_cmapss(path: str) -> pd.DataFrame:\n",
    "    # CMAPSS uses variable spaces -> \\s+ ; header absent\n",
    "    return pd.read_csv(path, sep=r\"\\s+\", header=None)\n",
    "\n",
    "def load_cmapss_flexible(data_root: str, subset: str):\n",
    "    tr, te, ru = _resolve_paths(data_root, subset)\n",
    "    print(\"Resolved paths:\")\n",
    "    print(\"  train ->\", tr)\n",
    "    print(\"  test  ->\", te)\n",
    "    print(\"  RUL   ->\", ru)\n",
    "    if not (tr and te and ru):\n",
    "        return None, None, None\n",
    "    df_tr = _read_cmapss(tr)\n",
    "    df_te = _read_cmapss(te)\n",
    "    rul   = _read_cmapss(ru).iloc[:,0]\n",
    "    # Map columns: engine_id, cycle, setting1..3, s1..sK (K typically 26)\n",
    "    def _map_cols(df):\n",
    "        n = df.shape[1]\n",
    "        base = [\"engine_id\",\"cycle\"] + [f\"setting{i}\" for i in range(1,4)]\n",
    "        k = n - len(base)\n",
    "        sensors = [f\"s{i}\" for i in range(1, k+1)]\n",
    "        m = df.copy(); m.columns = base + sensors\n",
    "        return m, sensors\n",
    "    df_tr, s_tr = _map_cols(df_tr)\n",
    "    df_te, s_te = _map_cols(df_te)\n",
    "    assert s_tr == s_te, \"Train/Test sensor schema mismatch\"\n",
    "    return df_tr, df_te, rul\n",
    "\n",
    "# Try load; else synthesize\n",
    "train_df, test_df, rul_series = load_cmapss_flexible(DATA_ROOT, DATASET)\n",
    "if train_df is None:\n",
    "    if not USE_SYNTH_IF_MISSING:\n",
    "        raise FileNotFoundError(\"CMAPSS files not found. Set DATA_ROOT correctly or enable synthesis.\")\n",
    "    print(f\"⚠️ {DATASET} not found in {os.path.abspath(DATA_ROOT)} — generating synthetic data...\")\n",
    "    # Synthetic CMAPSS-like generator\n",
    "    def synth_cmapss_like(n_engines=120, max_cycles=(180, 320), n_sensors=26):\n",
    "        rows = []\n",
    "        for eid in range(1, n_engines+1):\n",
    "            T = int(np.random.randint(*max_cycles))\n",
    "            s1 = np.clip(np.cumsum(np.random.randn(T)/100), -1, 1)\n",
    "            s2 = np.clip(np.cumsum(np.random.randn(T)/150), -1, 1)\n",
    "            s3 = np.clip(np.cumsum(np.random.randn(T)/200), -1, 1)\n",
    "            base = np.random.uniform(0.2, 0.8, size=n_sensors)\n",
    "            slope = np.random.uniform(-0.003, 0.003, size=n_sensors)\n",
    "            slope[1] = abs(slope[1]) + 0.004   # temp-like rises\n",
    "            slope[9] = -abs(slope[9]) - 0.004  # pressure-like falls\n",
    "            for t in range(1, T+1):\n",
    "                sensors = base + slope*t + 0.02*np.random.randn(n_sensors)\n",
    "                rows.append([eid,t,s1[t-1],s2[t-1],s3[t-1],*sensors])\n",
    "        cols = [\"engine_id\",\"cycle\"]+[f\"setting{i}\" for i in range(1,4)]+[f\"s{i}\" for i in range(1,n_sensors+1)]\n",
    "        return pd.DataFrame(rows, columns=cols)\n",
    "    train_df = synth_cmapss_like()\n",
    "    test_df = None; rul_series = None\n",
    "\n",
    "print(\"✅ train_df:\", train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "id": "10"
   },
   "source": [
    "## 3. RUL Labeling & Rolling Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "id": "11"
   },
   "source": [
    "### What this cell does\n",
    "\n",
    "- Defines helper functions: `add_rul, rolling_features, _hi`.\n",
    "- Engineers rolling-window features: `*_ma`, `*_std`, `*_diff`, plus a composite Health Index (HI) from z-scores.\n",
    "- All code remains unchanged; this cell-level note was added for clarity and maintainability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "id": "12",
    "outputId": "9b62f299-6473-45a8-ba87-0b9da1a11378"
   },
   "outputs": [],
   "source": [
    "def add_rul(df: pd.DataFrame, cap: int = RUL_CAP):\n",
    "    df = df.copy()\n",
    "    mx = df.groupby('engine_id')['cycle'].max().rename('max_cycle')\n",
    "    df = df.merge(mx, on='engine_id', how='left')\n",
    "    df['RUL'] = df['max_cycle'] - df['cycle']\n",
    "    if cap is not None:\n",
    "        df['RUL'] = df['RUL'].clip(upper=cap)\n",
    "    return df.drop(columns=['max_cycle'])\n",
    "\n",
    "train_df = add_rul(train_df, RUL_CAP)\n",
    "sensor_cols = [c for c in train_df.columns if c.startswith('s')]\n",
    "KEY_SENSORS = sensor_cols[:10]  # change to use all sensors if you want\n",
    "\n",
    "def rolling_features(df: pd.DataFrame, window:int=SEQ_WINDOW):\n",
    "    df = df.sort_values(['engine_id','cycle']).copy()\n",
    "    for c in KEY_SENSORS:\n",
    "        df[f'{c}_ma']   = df.groupby('engine_id')[c].transform(lambda x: x.rolling(window, min_periods=3).mean())\n",
    "        df[f'{c}_std']  = df.groupby('engine_id')[c].transform(lambda x: x.rolling(window, min_periods=3).std())\n",
    "        df[f'{c}_diff'] = df.groupby('engine_id')[c].diff()\n",
    "    # Health Index: per-engine z-norm then average; invert sign so higher=worse\n",
    "    def _hi(g):\n",
    "        arr = g[KEY_SENSORS].values\n",
    "        if arr.shape[0] < 5:\n",
    "            return pd.Series([np.nan]*len(g), index=g.index)\n",
    "        z = (arr - np.nanmean(arr, axis=0)) / (np.nanstd(arr, axis=0)+1e-6)\n",
    "        return pd.Series(-np.nanmean(z, axis=1), index=g.index)\n",
    "    df['HI'] = df.groupby('engine_id', group_keys=False).apply(_hi)\n",
    "    return df\n",
    "\n",
    "feat_df = rolling_features(train_df, window=SEQ_WINDOW)\n",
    "feat_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "id": "13"
   },
   "source": [
    "## 4. Engine-wise Split & Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "id": "14"
   },
   "source": [
    "### What this cell does\n",
    "\n",
    "- Resolves filesystem paths (e.g., `DATA_ROOT`, `DATASET`) and locates data files robustly.\n",
    "- Fits a feature scaler (e.g., `StandardScaler`) to normalize inputs consistently across train/validation/inference.\n",
    "- Splits data into training/validation (or uses cross-validation) to estimate generalization performance.\n",
    "- Engineers rolling-window features: `*_ma`, `*_std`, `*_diff`, plus a composite Health Index (HI) from z-scores.\n",
    "- All code remains unchanged; this cell-level note was added for clarity and maintainability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15",
    "outputId": "d0ee49ce-1b87-4ab3-cc53-3b83a183bf70"
   },
   "outputs": [],
   "source": [
    "engines = feat_df['engine_id'].unique()\n",
    "eng_tr, eng_va = train_test_split(engines, test_size=0.25, random_state=RANDOM_SEED)\n",
    "df_tr = feat_df[feat_df.engine_id.isin(eng_tr)].copy()\n",
    "df_va = feat_df[feat_df.engine_id.isin(eng_va)].copy()\n",
    "\n",
    "feature_cols = []\n",
    "for c in KEY_SENSORS:\n",
    "    feature_cols += [c, f'{c}_ma', f'{c}_std', f'{c}_diff']\n",
    "feature_cols += ['HI']\n",
    "\n",
    "X_tr = df_tr[feature_cols].fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
    "y_tr = df_tr['RUL']\n",
    "X_va = df_va[feature_cols].fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
    "y_va = df_va['RUL']\n",
    "\n",
    "scaler = RobustScaler() if USE_ROBUST_SCALER else StandardScaler()\n",
    "X_tr_s = scaler.fit_transform(X_tr)\n",
    "X_va_s = scaler.transform(X_va)\n",
    "dump(scaler, os.path.join(ARTIFACT_DIR,'scaler.joblib'))\n",
    "print('Shapes:', X_tr.shape, X_va.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "id": "16"
   },
   "source": [
    "## 5. Train Gradient Boosting (point + quantiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "id": "17"
   },
   "source": [
    "### What this cell does\n",
    "\n",
    "- Resolves filesystem paths (e.g., `DATA_ROOT`, `DATASET`) and locates data files robustly.\n",
    "- Trains a regression model for RUL prediction (e.g., `GradientBoostingRegressor`).\n",
    "- Trains quantile/interval models (e.g., P10 lower, P90 upper) to provide uncertainty bounds.\n",
    "- Fits models and performs predictions on validation or test data.\n",
    "- Computes evaluation metrics (MAE/RMSE/R²) to quantify prediction accuracy.\n",
    "- All code remains unchanged; this cell-level note was added for clarity and maintainability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "18",
    "outputId": "952eacd5-8612-40f5-d152-d13e6a677d22"
   },
   "outputs": [],
   "source": [
    "gb_point = GradientBoostingRegressor(random_state=RANDOM_SEED, n_estimators=300, learning_rate=0.05, max_depth=3)\n",
    "gb_point.fit(X_tr_s, y_tr)\n",
    "dump(gb_point, os.path.join(ARTIFACT_DIR,'gb_point.joblib'))\n",
    "\n",
    "gb_lo = GradientBoostingRegressor(loss='quantile', alpha=0.1, random_state=RANDOM_SEED, n_estimators=300, learning_rate=0.05, max_depth=3)\n",
    "gb_hi = GradientBoostingRegressor(loss='quantile', alpha=0.9, random_state=RANDOM_SEED, n_estimators=300, learning_rate=0.05, max_depth=3)\n",
    "gb_lo.fit(X_tr_s, y_tr); gb_hi.fit(X_tr_s, y_tr)\n",
    "dump(gb_lo, os.path.join(ARTIFACT_DIR,'gb_lo_p10.joblib'))\n",
    "dump(gb_hi, os.path.join(ARTIFACT_DIR,'gb_hi_p90.joblib'))\n",
    "\n",
    "pred_va = gb_point.predict(X_va_s)\n",
    "rmse = math.sqrt(mean_squared_error(y_va, pred_va))\n",
    "mae  = mean_absolute_error(y_va, pred_va)\n",
    "print({'val_RMSE': round(rmse,2), 'val_MAE': round(mae,2)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {
    "id": "19"
   },
   "source": [
    "### Validation Plot: True vs Predicted RUL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {
    "id": "20"
   },
   "source": [
    "### What this cell does\n",
    "\n",
    "- Produces visualizations (e.g., true vs predicted RUL, residual plots, or feature distributions).\n",
    "- All code remains unchanged; this cell-level note was added for clarity and maintainability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "21",
    "outputId": "eec906ed-f159-45c6-8dfa-9bbcec6c3e16"
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=y_va.values, y=pred_va, mode='markers', name='Val', opacity=0.55))\n",
    "mx = max(y_va.max(), pred_va.max())\n",
    "fig.add_trace(go.Scatter(x=[0,mx], y=[0,mx], mode='lines', name='Ideal', line=dict(dash='dash')))\n",
    "fig.update_layout(template='plotly_dark', title=f'{DATASET}: True vs Pred RUL', xaxis_title='True RUL', yaxis_title='Pred RUL')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {
    "id": "22"
   },
   "source": [
    "## 6. Test-Set Evaluation (uses RUL vector if available)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {
    "id": "23"
   },
   "source": [
    "### What this cell does\n",
    "\n",
    "- Defines helper functions: `build_feats, _hi`.\n",
    "- Fits models and performs predictions on validation or test data.\n",
    "- Computes evaluation metrics (MAE/RMSE/R²) to quantify prediction accuracy.\n",
    "- Engineers rolling-window features: `*_ma`, `*_std`, `*_diff`, plus a composite Health Index (HI) from z-scores.\n",
    "- All code remains unchanged; this cell-level note was added for clarity and maintainability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24",
    "outputId": "c03a244d-2c36-4f85-a6af-8158b92f82b7"
   },
   "outputs": [],
   "source": [
    "if test_df is not None and rul_series is not None:\n",
    "    # Build features on the full history, then score last cycle per engine\n",
    "    def build_feats(df):\n",
    "        df = df.sort_values(['engine_id','cycle']).copy()\n",
    "        for c in KEY_SENSORS:\n",
    "            df[f'{c}_ma']   = df.groupby('engine_id')[c].transform(lambda x: x.rolling(SEQ_WINDOW, min_periods=3).mean())\n",
    "            df[f'{c}_std']  = df.groupby('engine_id')[c].transform(lambda x: x.rolling(SEQ_WINDOW, min_periods=3).std())\n",
    "            df[f'{c}_diff'] = df.groupby('engine_id')[c].diff()\n",
    "        def _hi(g):\n",
    "            arr = g[KEY_SENSORS].values\n",
    "            if arr.shape[0] < 5:\n",
    "                return pd.Series([np.nan]*len(g), index=g.index)\n",
    "            z = (arr - np.nanmean(arr, axis=0)) / (np.nanstd(arr, axis=0)+1e-6)\n",
    "            return pd.Series(-np.nanmean(z, axis=1), index=g.index)\n",
    "        df['HI'] = df.groupby('engine_id', group_keys=False).apply(_hi)\n",
    "        return df\n",
    "    test_feat = build_feats(test_df)\n",
    "    last = test_feat.sort_values(['engine_id','cycle']).groupby('engine_id').tail(1)\n",
    "    Xt = last[feature_cols].fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
    "    Xts = scaler.transform(Xt)\n",
    "    y_pred_test = gb_point.predict(Xts)\n",
    "    y_true_test = rul_series.values.astype(float)\n",
    "    if len(y_true_test) == len(y_pred_test):\n",
    "        trmse = math.sqrt(mean_squared_error(y_true_test, y_pred_test))\n",
    "        tmae  = mean_absolute_error(y_true_test, y_pred_test)\n",
    "        print({'test_RMSE': round(trmse,2), 'test_MAE': round(tmae,2)})\n",
    "    else:\n",
    "        print(\"⚠️ Length mismatch: cannot compute test metrics.\")\n",
    "else:\n",
    "    print(\"(No test set available — skipped)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {
    "id": "25"
   },
   "source": [
    "## 7. Streaming Simulator (Plotly + ipywidgets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {
    "id": "26"
   },
   "source": [
    "### What this cell does\n",
    "\n",
    "- Imports libraries: `IPython.display, collections, ipywidgets, numpy, pandas, plotly.graph_objects, plotly.subplots, time` for data handling, ML, plotting, and utilities.\n",
    "- Resolves filesystem paths (e.g., `DATA_ROOT`, `DATASET`) and locates data files robustly.\n",
    "- Defines helper functions: `predict_with_interval, __init__, update, features, stream, tail, _on_start, _on_stop`.\n",
    "- Fits models and performs predictions on validation or test data.\n",
    "- Produces visualizations (e.g., true vs predicted RUL, residual plots, or feature distributions).\n",
    "- Engineers rolling-window features: `*_ma`, `*_std`, `*_diff`, plus a composite Health Index (HI) from z-scores.\n",
    "- All code remains unchanged; this cell-level note was added for clarity and maintainability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "9e0134a17d4c46d99f6b6fe1d9c3daff",
      "2e96111e36f24112a57106b9f77761f5",
      "9b695e55de40425ca5ec29e36dd317c2",
      "b0c4447dfaf04f8abd6e246b7b226990",
      "89d60d46e9cb4a2889e32d7db6f26844",
      "3974be1c880e43beb8873f75cc6e051a",
      "6fdd41025bd64f0984d5b3d9c044f5ec",
      "b83b5e3afcb64221b12ecb4bfdf10dc4",
      "4c97d22de6f94ca1985d38a2df4797ff",
      "ee4cdf26da134f159bb22347b5bc1a0f",
      "9d0a56f95159479ba8dfaaff053facfb",
      "ebf7fd37210c44ef87bca08c00b5bd05",
      "a7d410fc549a43a7af2ee037609a0f41",
      "aebd4bfe279d4e95a0dbcf3a389d9b65",
      "f6c110fa8aaa4275915339cdd777c9a9",
      "35aeebeebc4c417e8512f06a5831e810",
      "4dcef919859b46868257f582ed233191",
      "9d66cda7a611407789f9502323e6f1e3",
      "7b0b201fe79a4354b6727cdee401770c",
      "04631e7fb7034383a7cc06f2a77c8f42",
      "07cbeb4240f6487899ae9f5a29ee36c9",
      "d4cd2bb5d3834997879028f161209328",
      "10d5c515451e4944b675b2429f240ec3",
      "7ecc43c378974bb3a4d304d1464092b8",
      "5f86810944134416a23aa4f17f295a15",
      "1118d0f3605c4bff8f2ed0859968f5f3",
      "c6575746c25641c8bc6f87d7ca739a14",
      "4c974e63b16d4159bed84075b0bb3d6f"
     ]
    },
    "id": "27",
    "outputId": "45c5ecf9-cc44-4ab9-92f2-0c12fc06ae12"
   },
   "outputs": [],
   "source": [
    "# --- Cell 1: Start/Stop controls + streaming logic (no plots) ---\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Safety: required globals must exist\n",
    "_needed = [\"train_df\",\"scaler\",\"gb_point\",\"gb_lo\",\"gb_hi\",\"feature_cols\",\"KEY_SENSORS\",\"SEQ_WINDOW\"]\n",
    "_missing = [n for n in _needed if n not in globals()]\n",
    "assert not _missing, f\"Missing in notebook: {', '.join(_missing)}\"\n",
    "\n",
    "# ---------- Prediction + features ----------\n",
    "def predict_with_interval(feat_row: dict):\n",
    "    x  = pd.DataFrame([feat_row])[feature_cols].fillna(0)\n",
    "    xs = scaler.transform(x)\n",
    "    p  = float(gb_point.predict(xs)[0])\n",
    "    lo = float(gb_lo.predict(xs)[0])\n",
    "    hi = float(gb_hi.predict(xs)[0])\n",
    "    return p, lo, hi\n",
    "\n",
    "class OnlineState:\n",
    "    def __init__(self, window:int=SEQ_WINDOW):\n",
    "        from collections import deque\n",
    "        self.hist = deque(maxlen=window)\n",
    "        self.window = window\n",
    "    def update(self, row):\n",
    "        self.hist.append(row)\n",
    "        return self.features()\n",
    "    def features(self):\n",
    "        if len(self.hist) < 2:\n",
    "            return None\n",
    "        h = pd.DataFrame(list(self.hist))\n",
    "        feats = {}\n",
    "        for c in KEY_SENSORS:\n",
    "            s = h[c].astype(float)\n",
    "            feats[c] = float(s.iloc[-1])\n",
    "            feats[f\"{c}_ma\"]  = float(s.mean())\n",
    "            std_val = float(s.std())\n",
    "            feats[f\"{c}_std\"] = std_val if std_val == std_val else 0.0\n",
    "            feats[f\"{c}_diff\"] = float(s.iloc[-1] - s.iloc[-2]) if len(s) > 1 else 0.0\n",
    "        arr = h[KEY_SENSORS].to_numpy(dtype=float)\n",
    "        mu  = np.nanmean(arr, axis=0)\n",
    "        sd  = np.nanstd(arr, axis=0) + 1e-6\n",
    "        z   = (arr - mu) / sd\n",
    "        feats[\"HI\"] = -float(np.nanmean(z))\n",
    "        return feats\n",
    "\n",
    "def build_series_for_engine(engine_id:int) -> pd.DataFrame:\n",
    "    return (train_df.loc[train_df.engine_id == engine_id]\n",
    "            .sort_values('cycle')\n",
    "            .reset_index(drop=True))\n",
    "\n",
    "# ---------- Hooks that the plot cell will define ----------\n",
    "# The plot cell must assign these symbols to real functions/objects\n",
    "PLOT_HOOKS = {\n",
    "    \"on_status\": None,   # fn(str) -> None\n",
    "    \"on_step\":   None,   # fn(cycle, s2, hi, p, lo, hi, lastn) -> None\n",
    "    \"on_reset\":  None,   # fn() -> None      (clear traces/buffers)\n",
    "    \"set_max\":   None,   # fn(n:int) -> None (progress max)\n",
    "    \"set_val\":   None,   # fn(v:int) -> None (progress value)\n",
    "}\n",
    "\n",
    "# ---------- Widgets (controls shown first, as requested) ----------\n",
    "default_engine = int(train_df['engine_id'].value_counts().idxmax())\n",
    "engine_id_w = widgets.BoundedIntText(\n",
    "    value=default_engine,\n",
    "    min=int(train_df.engine_id.min()),\n",
    "    max=int(train_df.engine_id.max()),\n",
    "    description='Engine:',\n",
    "    layout=widgets.Layout(width=\"200px\")\n",
    ")\n",
    "speed_w  = widgets.Dropdown(options=[('1×',1),('5×',5),('20×',20)], value=5, description='Speed:')\n",
    "lastn_w  = widgets.IntSlider(min=50, max=500, step=10, value=200, description='Last N:')\n",
    "start_b  = widgets.Button(description='Start', button_style='success', icon='play')\n",
    "stop_b   = widgets.Button(description='Stop',  button_style='warning', icon='stop')\n",
    "status_o = widgets.HTML(\"<b>Status:</b> idle\")\n",
    "progress = widgets.IntProgress(min=0, max=100, value=0, bar_style='')\n",
    "\n",
    "controls = widgets.HBox([engine_id_w, speed_w, lastn_w, start_b, stop_b])\n",
    "display(controls, widgets.HBox([status_o, widgets.Label(\"  \"), progress]))\n",
    "\n",
    "# ---------- Streaming loop (no plotting here) ----------\n",
    "running = {\"flag\": False}\n",
    "\n",
    "def _emit_status(msg: str):\n",
    "    status_o.value = f\"<b>Status:</b> {msg}\"\n",
    "    if callable(PLOT_HOOKS[\"on_status\"]):\n",
    "        PLOT_HOOKS[\"on_status\"](msg)\n",
    "\n",
    "def stream_series(edf: pd.DataFrame, window:int, speed:int, lastn:int):\n",
    "    nrows = len(edf)\n",
    "    if nrows < 3:\n",
    "        _emit_status(f\"Not enough cycles to stream (n={nrows}).\")\n",
    "        return\n",
    "    if callable(PLOT_HOOKS[\"set_max\"]):\n",
    "        PLOT_HOOKS[\"set_max\"](nrows)\n",
    "    if callable(PLOT_HOOKS[\"on_reset\"]):\n",
    "        PLOT_HOOKS[\"on_reset\"]()\n",
    "\n",
    "    state = OnlineState(window=window)\n",
    "    running['flag'] = True\n",
    "    _emit_status(f\"streaming ({nrows} cycles)\")\n",
    "\n",
    "    step_count = 0\n",
    "    for _, row in edf.iterrows():\n",
    "        if not running['flag']:\n",
    "            _emit_status(\"stopped.\")\n",
    "            break\n",
    "        feats = state.update(row)\n",
    "        step_count += 1\n",
    "        if callable(PLOT_HOOKS[\"set_val\"]):\n",
    "            PLOT_HOOKS[\"set_val\"](step_count)\n",
    "        if feats is None:\n",
    "            time.sleep(max(0.01, 0.2/float(speed)))\n",
    "            continue\n",
    "\n",
    "        p, lo, hi = predict_with_interval(feats)\n",
    "        s2_val = float(row.get('s2', np.nan)) if 's2' in row else np.nan\n",
    "        cycle  = int(row['cycle'])\n",
    "\n",
    "        if callable(PLOT_HOOKS[\"on_step\"]):\n",
    "            PLOT_HOOKS[\"on_step\"](cycle, s2_val, float(feats[\"HI\"]), float(p), float(lo), float(hi), lastn)\n",
    "\n",
    "        time.sleep(max(0.01, 0.2/float(speed)))\n",
    "\n",
    "    if running['flag']:\n",
    "        _emit_status(\"finished.\")\n",
    "    running['flag'] = False\n",
    "\n",
    "def _on_start(_):\n",
    "    if running['flag']:\n",
    "        return\n",
    "    eid   = int(engine_id_w.value)\n",
    "    speed = int(speed_w.value)\n",
    "    lastn = int(lastn_w.value)\n",
    "    edf   = build_series_for_engine(eid)\n",
    "    try:\n",
    "        stream_series(edf=edf, window=int(SEQ_WINDOW), speed=speed, lastn=lastn)\n",
    "    except Exception as e:\n",
    "        running['flag'] = False\n",
    "        _emit_status(f\"error: {e}\")\n",
    "\n",
    "def _on_stop(_):\n",
    "    running['flag'] = False\n",
    "    _emit_status(\"stop requested (will stop at next step).\")\n",
    "\n",
    "start_b.on_click(_on_start)\n",
    "stop_b.on_click(_on_stop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717,
     "referenced_widgets": [
      "33812874bc71438b92b8fd1d8daf2108"
     ]
    },
    "id": "raVh4RdT8Bzr",
    "outputId": "2dbdf25c-c5a3-4ee6-8fcd-28aa348391d1"
   },
   "outputs": [],
   "source": [
    "# --- Cell 2: Plot creation + hook wiring (run after Cell 1) ---\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Create the figure\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=1, shared_xaxes=True, vertical_spacing=0.07,\n",
    "    subplot_titles=(\"Sensor s2\", \"Health Index (HI)\", \"Predicted RUL (10–90%)\")\n",
    ")\n",
    "fig.add_trace(go.Scatter(mode='lines', name='s2'), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(mode='lines', name='HI'), row=2, col=1)\n",
    "fig.add_trace(go.Scatter(mode='lines', name='RUL'), row=3, col=1)\n",
    "fig.add_trace(go.Scatter(mode='lines', name='RUL lo', line=dict(dash='dot')), row=3, col=1)\n",
    "fig.add_trace(go.Scatter(mode='lines', name='RUL hi', line=dict(dash='dot')), row=3, col=1)\n",
    "fig.update_layout(height=700, template='plotly_dark', showlegend=True)\n",
    "fw = go.FigureWidget(fig)\n",
    "display(fw)\n",
    "\n",
    "# Local buffers\n",
    "xs, s2s, his, pr, prl, prh = [], [], [], [], [], []\n",
    "\n",
    "# Progress and status come from Cell 1's widgets if present\n",
    "# Otherwise, define no-op fallbacks\n",
    "def _noop(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "# Hook implementations\n",
    "def _on_reset():\n",
    "    xs.clear(); s2s.clear(); his.clear(); pr.clear(); prl.clear(); prh.clear()\n",
    "    with fw.batch_update():\n",
    "        for tr in fw.data:\n",
    "            tr.x = []; tr.y = []\n",
    "\n",
    "def _on_status(msg: str):\n",
    "    # If Cell 1's status_o exists, it already shows. No need to duplicate.\n",
    "    _ = msg  # placeholder, customize if you want a second status display here.\n",
    "\n",
    "def _on_step(cycle, s2_val, hi_val, p, lo, hi, lastn):\n",
    "    xs.append(cycle); s2s.append(s2_val); his.append(hi_val); pr.append(p); prl.append(lo); prh.append(hi)\n",
    "    def tail(a): return a[-lastn:]\n",
    "    with fw.batch_update():\n",
    "        fw.data[0].x = tail(xs); fw.data[0].y = tail(s2s)\n",
    "        fw.data[1].x = tail(xs); fw.data[1].y = tail(his)\n",
    "        fw.data[2].x = tail(xs); fw.data[2].y = tail(pr)\n",
    "        fw.data[3].x = tail(xs); fw.data[3].y = tail(prl)\n",
    "        fw.data[4].x = tail(xs); fw.data[4].y = tail(prh)\n",
    "\n",
    "# Progress wiring (use Cell 1 widgets if available)\n",
    "try:\n",
    "    def _set_max(n:int):\n",
    "        progress.max = n\n",
    "    def _set_val(v:int):\n",
    "        progress.value = v\n",
    "except NameError:\n",
    "    _set_max = _noop\n",
    "    _set_val = _noop\n",
    "\n",
    "# Register hooks\n",
    "PLOT_HOOKS[\"on_reset\"] = _on_reset\n",
    "PLOT_HOOKS[\"on_status\"] = _on_status\n",
    "PLOT_HOOKS[\"on_step\"] = _on_step\n",
    "PLOT_HOOKS[\"set_max\"] = _set_max\n",
    "PLOT_HOOKS[\"set_val\"] = _set_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {
    "id": "28"
   },
   "source": [
    "## 8. Save Artifacts & Model Card"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {
    "id": "29"
   },
   "source": [
    "### What this cell does\n",
    "\n",
    "- Resolves filesystem paths (e.g., `DATA_ROOT`, `DATASET`) and locates data files robustly.\n",
    "- Computes evaluation metrics (MAE/RMSE/R²) to quantify prediction accuracy.\n",
    "- Writes a `model_card.json` with dataset, features, metrics, and training configuration metadata.\n",
    "- Engineers rolling-window features: `*_ma`, `*_std`, `*_diff`, plus a composite Health Index (HI) from z-scores.\n",
    "- All code remains unchanged; this cell-level note was added for clarity and maintainability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "30",
    "outputId": "e01af762-ab73-4e1e-d44c-4561cbcf8c12"
   },
   "outputs": [],
   "source": [
    "card = {\n",
    "  'project': 'Digital Twin — CMAPSS RUL',\n",
    "  'subset': DATASET,\n",
    "  'timestamp': datetime.utcnow().isoformat()+'Z',\n",
    "  'schema': 'engine_id, cycle, settings(3), sensors(s1..sK)',\n",
    "  'window': SEQ_WINDOW,\n",
    "  'rul_cap': RUL_CAP,\n",
    "  'features_used': feature_cols,\n",
    "  'metrics': {'val_RMSE': float(round(rmse,3)), 'val_MAE': float(round(mae,3))}\n",
    "}\n",
    "with open(os.path.join(ARTIFACT_DIR,'model_card.json'),'w') as f:\n",
    "    json.dump(card, f, indent=2)\n",
    "print('Artifacts in', ARTIFACT_DIR, ':', os.listdir(ARTIFACT_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {
    "id": "31"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Made with ❤️ by Shreyas Gowda.**  \n",
    "Explanatory comments were added with the help of GPT to provide detailed, teacher-style documentation.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
